id: fhv_data
namespace: zoomcamp
description: |
  The CSV Data used in the course: https://github.com/DataTalksClub/nyc-tlc-data/releases

concurrency:
  limit: 1


variables:
  file: "fhv_tripdata_{{ trigger.date | date ('yyyy-MM')}}.csv"
  staging_table: "public.fhv_tripdata_staging"
  table: "public.fhv_tripdata"
  data: "{{outputs.extract.outputFiles['fhv_tripdata_' ~ (trigger.date | date('yyyy-MM')) ~ '.csv']}}"


tasks:
  - id: set_label
    type: io.kestra.plugin.core.execution.Labels
    labels:
      file: "{{render(vars.file)}}"

  - id: extract
    type: io.kestra.plugin.scripts.shell.Commands
    outputFiles:
      - "*.csv"
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - wget -qO- https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/{{render(vars.file)}}.gz | gunzip > {{render(vars.file)}}

  - id: fhv_create_table
    type: io.kestra.plugin.jdbc.postgresql.Queries
    sql: |
          CREATE TABLE IF NOT EXISTS {{render(vars.table)}} (
              unique_row_id text,
              filename text,
              dispatching_base_num text,
              pickup_datetime timestamp,
              dropOff_datetime timestamp,
              PUlocationID text,
              DOlocationID text,
              SR_Flag text,
              Affiliated_base_number text
          );

  - id: fhv_create_staging_table
    type: io.kestra.plugin.jdbc.postgresql.Queries
    sql: |
          CREATE TABLE IF NOT EXISTS {{render(vars.staging_table)}} (
              unique_row_id text,
              filename text,
              dispatching_base_num text,
              pickup_datetime timestamp,
              dropOff_datetime timestamp,
              PUlocationID text,
              DOlocationID text,
              SR_Flag text,
              Affiliated_base_number text
          );

  - id: fhv_truncate_staging_table
    type: io.kestra.plugin.jdbc.postgresql.Queries
    sql: |
          TRUNCATE TABLE {{render(vars.staging_table)}};

  - id: fhv_copy_in_to_staging_table
    type: io.kestra.plugin.jdbc.postgresql.CopyIn
    format: CSV
    from: "{{render(vars.data)}}"
    table: "{{render(vars.staging_table)}}"
    header: true
    columns: [dispatching_base_num,pickup_datetime,dropOff_datetime,PUlocationID,DOlocationID,SR_Flag,Affiliated_base_number]

  - id: fhv_add_unique_id_and_filename
    type: io.kestra.plugin.jdbc.postgresql.Queries
    sql: |
          UPDATE {{render(vars.staging_table)}}
          SET 
            unique_row_id = md5(
              COALESCE(CAST(dispatching_base_num AS text), '') ||
              COALESCE(CAST(pickup_datetime AS text), '') || 
              COALESCE(CAST(dropOff_datetime AS text), '') || 
              COALESCE(PULocationID, '') || 
              COALESCE(DOLocationID, '') || 
              COALESCE(CAST(SR_Flag AS text), '') || 
              COALESCE(CAST(Affiliated_base_number AS text), '')      
            ),
            filename = '{{render(vars.file)}}';

  - id: fhv_merge_data
    type: io.kestra.plugin.jdbc.postgresql.Queries
    sql: |
          MERGE INTO {{render(vars.table)}} AS T
          USING {{render(vars.staging_table)}} AS S
          ON T.unique_row_id = S.unique_row_id
          WHEN NOT MATCHED THEN
            INSERT (
              unique_row_id, filename, dispatching_base_num,pickup_datetime,dropOff_datetime,PUlocationID,DOlocationID,SR_Flag,Affiliated_base_number
            )
            VALUES (
              S.unique_row_id, S.filename, S.dispatching_base_num, S.pickup_datetime, S.dropOff_datetime, S.PUlocationID, S.DOlocationID, S.SR_Flag, S.Affiliated_base_number
            );
  - id: purge_files
    type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles
    description: To avoid cluttering your storage, we will remove the downloaded files

pluginDefaults:
  - type: io.kestra.plugin.jdbc.postgresql
    values:
      url: jdbc:postgresql://host.docker.internal:5431/postgres-zoomcamp
      username: kestra
      password: k3str4

triggers:
  - id: fhv_schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "0 9 1 * *"
